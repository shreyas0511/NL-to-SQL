{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "339c8ccd",
   "metadata": {},
   "source": [
    "##### Testing the persistent storage logic\n",
    "\n",
    "* Main idea: each chat thread will have a session uuid\n",
    "* map the db uploaded in each thread and memory (human, ai messages) to that uuid\n",
    "* store memory as a json file on disk that can be loaded whenever the user goes back to a particular thread and wants to access previous messages in the chat history\n",
    "* use lazy loading to load chat history.\n",
    "* bootstrap script: on startup, enumerate all uuid.json memory files and recover past session uuids to persist session data on new start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f5ae705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder structure to store memory and db files\n",
    "# /data/memory\n",
    "# /data/db\n",
    "\n",
    "import os\n",
    "\n",
    "data_directory = \"storage/\"\n",
    "memory_directory = data_directory+\"memory\"\n",
    "db_directory = data_directory+\"db\"\n",
    "os.makedirs(data_directory, exist_ok=True)\n",
    "os.makedirs(memory_directory, exist_ok=True)\n",
    "os.makedirs(db_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae332d9",
   "metadata": {},
   "source": [
    "Each file in the storage/memory directory will be a uuid.json file with memory as json for each chat session with that uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58489dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# initialize empty .json and .db files to simulate pre-existing message and dbs\n",
    "for i in range(10):\n",
    "    current_session_id = str(uuid.uuid4())\n",
    "    db_file_path = os.path.join(db_directory, current_session_id+\".db\")\n",
    "    memory_file_path = os.path.join(memory_directory, current_session_id+\".json\")\n",
    "\n",
    "    with open(db_file_path, \"w\") as f:\n",
    "        pass\n",
    "\n",
    "    with open(memory_file_path, \"w\") as f:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852c3a41",
   "metadata": {},
   "source": [
    "Add dummy chat history to all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "931fb4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.messages.base import message_to_dict\n",
    "from langchain_core.messages.utils import messages_from_dict\n",
    "import json\n",
    "\n",
    "for file in os.listdir(memory_directory):\n",
    "    messages = []\n",
    "    for i in range(10):\n",
    "        messages.extend([\n",
    "            HumanMessage(content=\"sample human query\"),\n",
    "            AIMessage(content=\"sample AI response\")\n",
    "        ])\n",
    "    dict_data = [message_to_dict(message) for message in messages]\n",
    "    file_path = os.path.join(memory_directory, file)\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(dict_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8df2d6",
   "metadata": {},
   "source": [
    "Now, we have 10 .json files with chat history\n",
    "Now, we write the bootstrap script which runs on startup, collects all past session ids and maps them for lazy loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a102bb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10d2bc47-a28d-4e10-87cf-3d0249c41551': {'memory': None, 'db': None},\n",
       " '3fd1836d-9e20-43f2-9436-54e9a8f09494': {'memory': None, 'db': None},\n",
       " '921058a2-2956-4d05-bd4d-9dbb05d9b7ed': {'memory': None, 'db': None},\n",
       " 'b96a9ad6-ea59-4b72-8ac2-e3d53dc1f8b7': {'memory': None, 'db': None},\n",
       " 'c92b07d2-5f2f-436d-a530-453b69b6a6c8': {'memory': None, 'db': None},\n",
       " 'd7cee794-a03f-468f-a342-da06d1f2fb20': {'memory': None, 'db': None},\n",
       " 'd975ea2c-6aff-4c11-b563-53fb054a08a0': {'memory': None, 'db': None},\n",
       " 'dfe06996-aa76-404d-ae65-63f4602be651': {'memory': None, 'db': None},\n",
       " 'e992b789-9ba3-40da-9d8d-b35a162649f5': {'memory': None, 'db': None},\n",
       " 'ffde8f05-bcb9-4e54-a286-f4f0b4664b08': {'memory': None, 'db': None}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_map = {}\n",
    "session_file_map = {}\n",
    "\n",
    "for file in os.listdir(memory_directory):\n",
    "    uuid = file[:-5]\n",
    "    session_map[uuid] = {\"memory\":None, \"db\":None}\n",
    "    session_file_map[uuid] = {\"memory_file\": os.path.join(memory_directory, file), \n",
    "                              \"db_file\":os.path.join(db_directory, uuid+\".db\")}\n",
    "\n",
    "session_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07fdb75",
   "metadata": {},
   "source": [
    "Lazy load memory and db for a given uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55faa3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'human', 'data': {'content': 'sample human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'sample AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}, {'type': 'human', 'data': {'content': 'sample human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'sample AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}, {'type': 'human', 'data': {'content': 'sample human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'sample AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}, {'type': 'human', 'data': {'content': 'sample human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'sample AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}, {'type': 'human', 'data': {'content': 'sample human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'sample AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}, {'type': 'human', 'data': {'content': 'sample human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'sample AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}, {'type': 'human', 'data': {'content': 'sample human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'sample AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}, {'type': 'human', 'data': {'content': 'sample human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'sample AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}, {'type': 'human', 'data': {'content': 'sample human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'sample AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}, {'type': 'human', 'data': {'content': 'sample human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'sample AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}, {'type': 'human', 'data': {'content': 'new human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'new AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}]\n",
      "[{'type': 'human', 'data': {'content': 'sample human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'sample AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}, {'type': 'human', 'data': {'content': 'sample human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'sample AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}, {'type': 'human', 'data': {'content': 'sample human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'sample AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}, {'type': 'human', 'data': {'content': 'sample human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'sample AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}, {'type': 'human', 'data': {'content': 'sample human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'sample AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}, {'type': 'human', 'data': {'content': 'sample human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'sample AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}, {'type': 'human', 'data': {'content': 'sample human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'sample AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}, {'type': 'human', 'data': {'content': 'sample human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'sample AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}, {'type': 'human', 'data': {'content': 'sample human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'sample AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}, {'type': 'human', 'data': {'content': 'sample human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'sample AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}, {'type': 'human', 'data': {'content': 'new human query', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None}}, {'type': 'ai', 'data': {'content': 'new AI response', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}]\n",
      "22\n",
      "{'10d2bc47-a28d-4e10-87cf-3d0249c41551': {'memory': None, 'db': None}, '3fd1836d-9e20-43f2-9436-54e9a8f09494': {'memory': None, 'db': None}, '921058a2-2956-4d05-bd4d-9dbb05d9b7ed': {'memory': None, 'db': None}, 'b96a9ad6-ea59-4b72-8ac2-e3d53dc1f8b7': {'memory': [HumanMessage(content='sample human query', additional_kwargs={}, response_metadata={}), AIMessage(content='sample AI response', additional_kwargs={}, response_metadata={}), HumanMessage(content='sample human query', additional_kwargs={}, response_metadata={}), AIMessage(content='sample AI response', additional_kwargs={}, response_metadata={}), HumanMessage(content='sample human query', additional_kwargs={}, response_metadata={}), AIMessage(content='sample AI response', additional_kwargs={}, response_metadata={}), HumanMessage(content='sample human query', additional_kwargs={}, response_metadata={}), AIMessage(content='sample AI response', additional_kwargs={}, response_metadata={}), HumanMessage(content='sample human query', additional_kwargs={}, response_metadata={}), AIMessage(content='sample AI response', additional_kwargs={}, response_metadata={}), HumanMessage(content='sample human query', additional_kwargs={}, response_metadata={}), AIMessage(content='sample AI response', additional_kwargs={}, response_metadata={}), HumanMessage(content='sample human query', additional_kwargs={}, response_metadata={}), AIMessage(content='sample AI response', additional_kwargs={}, response_metadata={}), HumanMessage(content='sample human query', additional_kwargs={}, response_metadata={}), AIMessage(content='sample AI response', additional_kwargs={}, response_metadata={}), HumanMessage(content='sample human query', additional_kwargs={}, response_metadata={}), AIMessage(content='sample AI response', additional_kwargs={}, response_metadata={}), HumanMessage(content='sample human query', additional_kwargs={}, response_metadata={}), AIMessage(content='sample AI response', additional_kwargs={}, response_metadata={}), HumanMessage(content='new human query', additional_kwargs={}, response_metadata={}), AIMessage(content='new AI response', additional_kwargs={}, response_metadata={})], 'db': 'storage/db\\\\b96a9ad6-ea59-4b72-8ac2-e3d53dc1f8b7.db'}, 'c92b07d2-5f2f-436d-a530-453b69b6a6c8': {'memory': None, 'db': None}, 'd7cee794-a03f-468f-a342-da06d1f2fb20': {'memory': None, 'db': None}, 'd975ea2c-6aff-4c11-b563-53fb054a08a0': {'memory': None, 'db': None}, 'dfe06996-aa76-404d-ae65-63f4602be651': {'memory': None, 'db': None}, 'e992b789-9ba3-40da-9d8d-b35a162649f5': {'memory': None, 'db': None}, 'ffde8f05-bcb9-4e54-a286-f4f0b4664b08': {'memory': None, 'db': None}}\n"
     ]
    }
   ],
   "source": [
    "sample_uuid = \"b96a9ad6-ea59-4b72-8ac2-e3d53dc1f8b7\"\n",
    "\n",
    "# for the given uuid, fetch the .json and .db files\n",
    "memory_file = session_file_map[sample_uuid][\"memory_file\"]\n",
    "db_file = session_file_map[sample_uuid][\"db_file\"]\n",
    "\n",
    "# read all contents of the memory file into a list and add the new Human,AI message pairs\n",
    "with open(memory_file, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(data)\n",
    "\n",
    "# populate the session_map with extracted chat history/ memory\n",
    "msg_data = messages_from_dict(data)\n",
    "session_map[sample_uuid][\"memory\"] = msg_data\n",
    "session_map[sample_uuid][\"db\"] = os.path.join(db_directory, sample_uuid+\".db\")\n",
    "print(data)\n",
    "print(len(data))\n",
    "print(session_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece3f9a0",
   "metadata": {},
   "source": [
    "Let's display the past history line by line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3935ec00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--->  sample human query\n",
      "--->  sample AI response\n",
      "--->  sample human query\n",
      "--->  sample AI response\n",
      "--->  sample human query\n",
      "--->  sample AI response\n",
      "--->  sample human query\n",
      "--->  sample AI response\n",
      "--->  sample human query\n",
      "--->  sample AI response\n",
      "--->  sample human query\n",
      "--->  sample AI response\n",
      "--->  sample human query\n",
      "--->  sample AI response\n",
      "--->  sample human query\n",
      "--->  sample AI response\n",
      "--->  sample human query\n",
      "--->  sample AI response\n",
      "--->  sample human query\n",
      "--->  sample AI response\n",
      "--->  new human query\n",
      "--->  new AI response\n"
     ]
    }
   ],
   "source": [
    "# display to UI later\n",
    "for msg in session_map[sample_uuid][\"memory\"]:\n",
    "    print(\"---> \", msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281513df",
   "metadata": {},
   "source": [
    "Now that we have the memory data from that session's json file, we can append new Human, AI message objects to this list and save the entire file again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b497fef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_message = [HumanMessage(content=\"new human query\"), AIMessage(content=\"new AI response\")]\n",
    "\n",
    "data.extend([message_to_dict(msg) for msg in new_message])\n",
    "\n",
    "file_path = os.path.join(memory_directory, sample_uuid+\".json\")\n",
    "with open(file_path, \"w\") as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639980d9",
   "metadata": {},
   "source": [
    "Once we switch to a new session uuid, we can clear the memory from the session map to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0dfa6a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10d2bc47-a28d-4e10-87cf-3d0249c41551': {'memory': None, 'db': None}, '3fd1836d-9e20-43f2-9436-54e9a8f09494': {'memory': None, 'db': None}, '921058a2-2956-4d05-bd4d-9dbb05d9b7ed': {'memory': None, 'db': None}, 'b96a9ad6-ea59-4b72-8ac2-e3d53dc1f8b7': {'memory': None, 'db': None}, 'c92b07d2-5f2f-436d-a530-453b69b6a6c8': {'memory': None, 'db': None}, 'd7cee794-a03f-468f-a342-da06d1f2fb20': {'memory': None, 'db': None}, 'd975ea2c-6aff-4c11-b563-53fb054a08a0': {'memory': None, 'db': None}, 'dfe06996-aa76-404d-ae65-63f4602be651': {'memory': None, 'db': None}, 'e992b789-9ba3-40da-9d8d-b35a162649f5': {'memory': None, 'db': None}, 'ffde8f05-bcb9-4e54-a286-f4f0b4664b08': {'memory': None, 'db': None}}\n"
     ]
    }
   ],
   "source": [
    "session_map[sample_uuid][\"memory\"] = None\n",
    "session_map[sample_uuid][\"db\"] = None\n",
    "print(session_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b0054b",
   "metadata": {},
   "source": [
    "ALL steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c4765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
